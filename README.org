* Headless Hunter

Stop hunting. Start matching.

*Headless Hunter* is a terminal-first, autonomous agent that cuts through the noise of modern job boards. It doesn't just search; it *scouts, scrapes, and analyzes* with a cynical eye to find only the roles that actually fit your profile.

** Demo

[[./assets/demo.gif]]

** Why?

1.  *Aggregator Hell*: Skip the "Ghost Jobs" and sponsored clutter of job boards.
2.  *Deep Intelligence*: Scrapes past the "Show More" buttons to analyze the full job description.
3.  *Privacy First*: Run the entire reasoning engine locally with Ollama. No data leaks.
4.  *Cynical Analysis*: The agent is trained to be skeptical, filtering out roles that don't match your technical depth.

** How it works

#+BEGIN_EXAMPLE
[Resume] + [Wishes]
      ↓
(LLM Profiler) → Formulates Search Strategy
      ↓
(The Harvester) → Deep Scrapes bypassing aggregators
      ↓
(Cynical Scout) → Aggressive Technical Filtering
      ↓
[High-Fidelity Report]
#+END_EXAMPLE

- *Broad Discovery (Tavily)*: Instead of relying on traditional search engines that are cluttered with SEO spam, we use Tavily's AI-native search to identify high-potential job URLs.
- *Deep Harvesting (Puppeteer)*: The "Harvester" uses a headless browser to bypass standard scrapers' limitations.
** Features

- *Intelligent Scouting*: LLM-driven planning that understands the *context* of your resume, not just keywords.
- *The Harvester*: A Puppeteer-based powerhouse that extracts full context from LinkedIn, Glassdoor, and direct career pages.
- *Cynical Analysis*: A specialized persona that cuts through HR-speak to find genuine technical alignment.
- *Nix-Powered*: A single command (~nix develop~) to get the entire stack (Bun, Puppeteer, etc) running.

** Prerequisites

- [[https://nixos.org/][Nix]] (flakes enabled) — *The only dependency you need to manage.*
- [[https://tavily.com/][Tavily API Key]] (for initial discovery)
- [[https://ollama.com/][Ollama]] — For 100% private, local inference.

** Quick Start

1.  *Shell Up*:
   #+BEGIN_SRC bash
   nix develop
   #+END_SRC
2.  *Configure*:
   Copy ~.env-example~ to ~.env~ and add your keys.
   (See the configuration strategy below for Local vs. Cloud).
3.  *Feed the Agent*:
   Drop your ~resume.md~ in the root.
   - *Tip*: If skipped, the agent will use ~tests/fixtures/resume_example.md~ as a fallback/demo.
4.  *Launch*:
   #+BEGIN_SRC bash
   bun run src/index.tsx
   #+END_SRC

** Advanced Configuration

The agent uses a dual-role strategy:
1.  **PROFILER**: Analyzes your resume/intent.
2.  **SCOUT**: Reads and analyzes job descriptions.

You can mix and match providers in your ~.env~:

#+BEGIN_SRC bash
# Example: Hybrid (Local for privacy, Cloud for speed)
LLM_PROVIDER_PROFILER=local
LLM_PROVIDER_SCOUT=google
GOOGLE_API_KEY=AIzaSy...
#+END_SRC

** Testing

Run the built-in test bench to verify the Harvester module:

#+BEGIN_SRC bash
bun run src/test_bench.ts
#+END_SRC

** Architecture

Built on a *RAG-enhanced Agentic Workflow* using *LangGraph*.

- *Agentic State Machine* (~src/state.ts~): Manages conversation history and long-term memory using a cyclic graph architecture.
- *Reasoning Engine* (~src/nodes.ts~): Uses Chain-of-Thought (CoT) to plan, execute, and refine search strategies.
- *Hybrid RAG Pipeline* (~src/tools.ts~): Combines broad API search (Tavily) with deep, headless browser scraping (Puppeteer) to feed high-fidelity data into the context window.
- *Model Abstraction* (~src/model_factory.ts~): Supports both Local Inference (Edge AI via Ollama) and Cloud LLMs (Gemini) through a unified interface.

** License

MIT
